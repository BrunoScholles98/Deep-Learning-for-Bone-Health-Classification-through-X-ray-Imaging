{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_EMrcidbcfJ"
   },
   "source": [
    "<h1>Visualizing Class-Specific Saliency Map in PyTorch's EfficientNet</h1>\n",
    "Saliency in an image refers to what is perceptible or important to the computer vision system. When applied to convolutional neural networks, the saliency map represents the essential pixels in the image that influence the network's prediction. This code has been adapted to create specific saliency maps for each class, with the goal of observing the points where the network concentrates its attention when classifying X-ray images related to bone health.\n",
    "\n",
    "The project focuses on improving the interpretability of convolutional networks by enabling the visualization of locations that the network deems relevant for decision-making regarding bone health. This saliency map technique is valuable for medical professionals and researchers as it provides insights into the specific features or patterns that the neural network uses for classification.\n",
    "\n",
    "Original source of the code: https://github.com/sunnynevarekar/pytorch-saliency-maps/tree/master\n",
    "\n",
    "<h1>Visualizando o Mapa de Saliência de Classe Específica na EfficientNet do PyTorch</h1>\n",
    "\n",
    "A saliência em uma imagem refere-se ao que é perceptível ou importante para o sistema de visão computacional. Quando aplicado em redes neurais convolucionais, o mapa de saliência representa os pixels essenciais na imagem que influenciam a previsão da rede. Este código foi adaptado para criar mapas de saliência específicos para cada classe, com o objetivo de observar os pontos em que a rede concentra sua atenção ao classificar imagens de raio-x relacionadas à saúde óssea.\n",
    "\n",
    "O projeto se concentra em melhorar a interpretabilidade das redes convolucionais ao permitir a visualização dos locais que a rede considera relevantes para a tomada de decisão em relação à saúde óssea. Essa técnica de mapa de saliência é valiosa para profissionais da área médica e pesquisadores, pois fornece insights sobre as características ou padrões específicos que a rede neural utiliza para realizar a classificação.\n",
    "\n",
    "Fonte original do código: https://github.com/sunnynevarekar/pytorch-saliency-maps/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZmo6jbkzPbg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EN: Loads the pre-trained weights into the model. Additionally, transformations are defined to preprocess and normalize the input images before passing them to the model during inference. The code also adjusts the expected size of the image based on the selected model.\n",
    "\n",
    "PT-BR: Carrega os pesos pré-treinados no modelo. Além disso, são definidas transformações para pré-processar e normalizar as imagens de entrada antes de passá-las para o modelo durante a inferência. O código também ajusta o tamanho esperado da imagem com base no modelo selecionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-WsN9PsezS4t",
    "outputId": "763d8578-a4ee-4a9a-d756-dd9354f1e361"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = '/d01/scholles/gigasistemica/saved_models/old/efficientnet-b7_AUG_RB_CVAT_Train_C1_C2C3_Croped_600x600_Batch4_100Ep/efficientnet-b7_AUG_RB_CVAT_Train_Saudavel_DoenteGeral_Croped_600x600_Batch4_100Ep.pth'\n",
    "MODEL = 'efficientnet-' + re.findall(r'efficientnet-(b\\d)', MODEL_PATH)[0] if re.findall(r'efficientnet-(b\\d)', MODEL_PATH) else None\n",
    "IMG_RESIZE_PATH = '/d01/scholles/gigasistemica/datasets/CVAT_train/augmented/AUG_RB_CVAT_Train_FULL_IMG_C1_C3/train/C1/OPHUB2019-220.jpg'\n",
    "PERSONALIZED_RESIZE = True\n",
    "PERS_RESIZE_NUM = 3\n",
    "TEST_IMGS_NUMBER = 20\n",
    "\n",
    "if PERSONALIZED_RESIZE == True:\n",
    "    RESIZE = ((lambda img: (img.size[1] // PERS_RESIZE_NUM, img.size[0] // PERS_RESIZE_NUM))(Image.open(IMG_RESIZE_PATH)))\n",
    "else:\n",
    "    resize_mapping = {'efficientnet-b0': (224, 224),\n",
    "                    'efficientnet-b1': (240, 240),\n",
    "                    'efficientnet-b2': (260, 260),\n",
    "                    'efficientnet-b3': (300, 300),\n",
    "                    'efficientnet-b4': (380, 380),\n",
    "                    'efficientnet-b5': (456, 456),\n",
    "                    'efficientnet-b6': (528, 528),\n",
    "                    'efficientnet-b7': (600, 600)}\n",
    "    \n",
    "    RESIZE = resize_mapping.get(MODEL, None)\n",
    "\n",
    "if 'C2C3' in MODEL_PATH:\n",
    "    diagnosticos = {0: 'Osso Saudável', 1: 'Osso Doente'}\n",
    "else:\n",
    "    diagnosticos = {0: 'Alta porosidade óssea não detectada', 1: 'Alta porosidade óssea detectada'}\n",
    "\n",
    "#load pretrained resnet model\n",
    "model = EfficientNet.from_pretrained(MODEL)\n",
    "state_dict = torch.load(MODEL_PATH)\n",
    "model.load_state_dict(state_dict)\n",
    "#print(model)\n",
    "\n",
    "#define transforms to preprocess input image into format expected by model\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "#inverse transform to get normalize image back to original form for visualization\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "    std=[1/0.229, 1/0.224, 1/0.255]\n",
    ")\n",
    "\n",
    "#transforms to resize image to the size expected by pretrained model,\n",
    "#convert PIL image to tensor, and\n",
    "#normalize the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(RESIZE),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EN: The code implements the saliency function, which takes an input image and a deep learning model. This function calculates and displays a saliency map, highlighting the relevant regions of the image for the model's predictions. The process involves preprocessing the image, computing the gradients of the highest scoring class with respect to the image, and normalizing the intensity of the gradients. Then, a hot colormap is applied to the saliency map, followed by thresholding to highlight the most important areas. The function creates a figure with three subplots showing the original image, the saliency map, and the overlay of the two. Additionally, the associated diagnosis for the image is displayed based on the model's predictions.\n",
    "\n",
    "PT-BR: O código implementa a função saliency, que recebe uma imagem de entrada e um modelo de aprendizado profundo. Essa função calcula e exibe um mapa de saliência, destacando as regiões relevantes da imagem para as previsões do modelo. O processo envolve pré-processamento da imagem, cálculo dos gradientes da classe de maior pontuação em relação à imagem e normalização da intensidade dos gradientes. Em seguida, é aplicado um colormap quente ao mapa de saliência e um thresholding para destacar as áreas mais importantes. A função cria uma figura com três subplots mostrando a imagem original, o mapa de saliência e a sobreposição das duas. Além disso, o diagnóstico associado à imagem é exibido com base nas previsões do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency(img, model):\n",
    "    #we don't need gradients w.r.t. weights for a trained model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    #set model in eval mode\n",
    "    model.eval()\n",
    "    #transoform input PIL image to torch.Tensor and normalize\n",
    "    input = transform(img)\n",
    "    input.unsqueeze_(0)\n",
    "\n",
    "    #we want to calculate gradient of higest score w.r.t. input\n",
    "    #so set requires_grad to True for input \n",
    "    input.requires_grad = True\n",
    "    #forward pass to calculate predictions\n",
    "    preds = model(input)\n",
    "    score, indices = torch.max(preds, 1)\n",
    "    #backward pass to get gradients of score predicted class w.r.t. input image\n",
    "    score.backward()\n",
    "    #get max along channel axis\n",
    "    slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
    "    #normalize to [0..1]\n",
    "    slc = (slc - slc.min())/(slc.max()-slc.min())\n",
    "        \n",
    "    #apply inverse transform on image\n",
    "    with torch.no_grad():\n",
    "        input_img = inv_normalize(input[0])\n",
    "        \n",
    "    imagem_hot = plt.cm.hot(slc)\n",
    "    original = np.clip(np.transpose(input_img.detach().numpy(), (1, 2, 0)), 0, 1)\n",
    "\n",
    "    # Multiplicar o canal vermelho da imagem \"hot\" pela intensidade desejada do vermelho\n",
    "    intensity = 1.5  # Intensidade do vermelho (ajuste conforme necessário)\n",
    "    red_channel = imagem_hot[:, :, 0] * intensity\n",
    "    \n",
    "    # Aplicar o threshold ao canal vermelho\n",
    "    threshold = 0.3\n",
    "    red_channel = np.where(red_channel < threshold, 0, red_channel)\n",
    "\n",
    "    # Sobrepor o canal vermelho modificado na imagem original\n",
    "    overlay = np.clip(original + red_channel[:, :, np.newaxis], 0, 1)\n",
    "        \n",
    "    # Plot the image, saliency map, and overlay\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(np.transpose(input_img.detach().numpy(), (1, 2, 0)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Original Image', fontweight='bold', color='white')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(slc.numpy(), cmap=plt.cm.hot)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Saliency Map', fontweight='bold', color='white')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(overlay)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Overlay', fontweight='bold', color='white')\n",
    "    \n",
    "    diagnosis = 'Diagnóstico: ' + diagnosticos[indices.item()]\n",
    "    plt.suptitle(diagnosis, fontsize=40, y=1.05, fontweight='bold', color='white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EN: The function select_random_images takes the path of a folder and the number of images num_images as arguments. The purpose of this function is to randomly select a certain number of images from the provided folder. Initially, the function lists all the files contained in the folder. Then, it filters only the files that are images based on their extensions (e.g., .png, .jpg, .jpeg, .gif). If the folder does not contain enough images for the specified quantity, the function raises a value exception to generate an error. Otherwise, the function uses the random module to randomly select the specified number of images from the list of image files. It then creates the full path for each selected image and returns a list containing these full paths.\n",
    "\n",
    "PT-BR: A função select_random_images recebe o caminho de uma pasta e um número de imagens num_images como argumentos. Essa função tem a finalidade de selecionar aleatoriamente um determinado número de imagens a partir da pasta fornecida. Inicialmente, a função lista todos os arquivos contidos na pasta. Em seguida, filtra apenas os arquivos que são imagens com base em suas extensões (por exemplo, .png, .jpg, .jpeg, .gif). Caso a pasta não contenha imagens suficientes para a quantidade especificada, a função gera um erro através do levantamento de uma exceção de valor. Caso contrário, a função utiliza o módulo random para selecionar aleatoriamente o número especificado de imagens da lista de arquivos de imagem. Em seguida, ela cria o caminho completo para cada imagem selecionada e retorna uma lista contendo esses caminhos completos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_images(folder_path, num_images=TEST_IMGS_NUMBER):\n",
    "    # Lista todos os arquivos da pasta\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filtra apenas os arquivos que são imagens (por extensão)\n",
    "    image_files = [file for file in all_files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "    \n",
    "    # Se a pasta não tiver imagens suficientes, trata o caso\n",
    "    if len(image_files) < num_images:\n",
    "        raise ValueError(\"A pasta não contém imagens suficientes.\")\n",
    "    \n",
    "    # Seleciona aleatoriamente num_images imagens\n",
    "    selected_images = random.sample(image_files, num_images)\n",
    "    \n",
    "    # Cria o caminho completo para cada imagem selecionada\n",
    "    image_paths = [os.path.join(folder_path, image) for image in selected_images]\n",
    "    \n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EN: A set of images is randomly selected from a specific directory. For each selected image, the saliency function is called to generate and display the saliency map of the image using the trained model.\n",
    "\n",
    "PT-BR: Um conjunto de imagens é selecionado aleatoriamente de um diretório específico. Para cada imagem selecionada, a função saliency é chamada para gerar e exibir o mapa de saliência da imagem usando o modelo treinado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>C3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_selecionadas = select_random_images('/d01/scholles/gigasistemica/datasets/CVAT_train/augmented/AUG_RB_NEW_CVAT_C1_C3_Cropped_600x600/test/C3')\n",
    "for img_path in imagens_selecionadas:\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    saliency(img, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>C2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_selecionadas = select_random_images('/d01/scholles/gigasistemica/datasets/CVAT_train/augmented/AUG_RB_NEW_CVAT_C1_C3_Cropped_600x600/test/C3')\n",
    "for img_path in imagens_selecionadas:\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    saliency(img, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>C1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_selecionadas = select_random_images('/d01/scholles/gigasistemica/datasets/CVAT_train/augmented/AUG_RB_NEW_CVAT_C1_C3_Cropped_600x600/test/C3')\n",
    "for img_path in imagens_selecionadas:\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    saliency(img, model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Saliency maps in pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
